
# ACG2025 Paper Reference Implementation

**Language:** [English](#english) | [日本語](#japanese)

## English

### 1. Overview

This project is a reference implementation of the method proposed in the paper "Mastering Othello with genetic algorithm and reinforcement learning". The implementation presents an efficient learning method for Othello that requires no domain knowledge beyond the game rules and board symmetries.

The method combines genetic algorithm-based n-tuple optimization with self-play reinforcement learning to achieve strong gameplay performance. The key innovation is using a Biased Random-Key Genetic Algorithm (BRKGA) to optimize n-tuple structures while generating training data through self-play, eliminating the need for existing game records or domain-specific strategic knowledge.

Specifically, it consists of the following two main phases:

1.  **N-Tuple Structure Optimization**: Using BRKGA to evolve optimal n-tuple shapes and combinations for feature extraction. Each individual in the genetic algorithm represents a set of spatially connected n-tuples, and fitness is defined as the reciprocal of the cross-entropy loss between the value function predictions and observed outcomes on test data, after training the value function using TD(λ) learning with that individual's n-tuples.
2.  **Self-Play Reinforcement Learning**: After obtaining optimized n-tuples, the method further refines the value function parameters through AlphaZero-style self-play using Monte Carlo Tree Search (MCTS), generating 500,000 games per training cycle.

The method achieves remarkable efficiency, completing training in approximately 38 hours on consumer hardware while achieving winning performance against strong Othello programs like Edax Level 10.

### 2. Directory and File Structure

The roles of the main directories and files in this project are as follows:

-   `ACG2025-reference-implementation.sln`: Visual Studio solution file.
-   `ACG2025-reference-implementation/`: Directory containing the project source code.
    -   `Program.cs`: Main entry point. The functionality (tool) executed is switched by symbols defined at build time.
    -   `Engines/`: Game engines including MCTS engine with PUCT algorithm and Alpha-Beta pruning engine with transposition table.
    -   `Evaluation/`: Classes related to evaluation functions.
    -   `Learn/`: Implementation of machine learning algorithms such as TD learning, self-play, and n-tuple optimization using BRKGA.
    -   `NTupleSystem/`: Classes for N-Tuple System structure and management.
    -   `Reversi/`: Basic game logic including Othello rules, board representation, and move generation.
    -   `Search/`: Implementation of search algorithms (alpha-beta search, MCTS).
    -   `Protocols/`: Interfaces for communication between game engines and external GUIs, such as NBoard protocol for integration with the NBoard GUI application ( http://www.orbanova.com/nboard/ ).
    -   `Utils/`: Auxiliary utility classes.
-   `ConfigFileTemplates/`: Templates for configuration files (`.json`) used by each tool. Copy these files to any working directory for use.
-   `VisualizationTools/`: Python scripts for visualizing results and data analysis.
    -   `draw_ntuples.py`: Visualizes n-tuple structures on an 8x8 board grid. Takes n-tuple definition files (`.txt`) as input and displays the spatial patterns.
    -   `plot_fitness_history.py`: Plots fitness evolution during BRKGA optimization. Takes fitness history files generated by the n-tuple optimizer and displays best, worst, median, and average fitness over generations.

### 3. Build Instructions

This project is developed with .NET 8. You can build it in an environment with .NET 8 SDK installed. Specify preprocessor symbols at build time according to the tool you want to use.

**Dependencies:**
This project depends on the following NuGet package:
- **MathNet.Numerics** (Version 5.0.0): Used for statistical distributions (specifically Dirichlet distribution) in the MCTS implementation.

The required NuGet packages will be automatically downloaded and installed when you run `dotnet build`.

The following commands show how to build each tool:

- **N-Tuple System Structure Optimization (OPTIMIZE_NTUPLE)**
  ```sh
  dotnet build -c Release -p:DefineConstants=OPTIMIZE_NTUPLE ACG2025-reference-implementation/ACG2025-reference-implementation.csproj
  ```

- **Self-Play Reinforcement Learning (RL_SELFPLAY)**
  ```sh
  dotnet build -c Release -p:DefineConstants=RL_SELFPLAY ACG2025-reference-implementation/ACG2025-reference-implementation.csproj
  ```

- **Evaluation Function Generation from Pool (DECODE_POOL)**
  ```sh
  dotnet build -c Release -p:DefineConstants=DECODE_POOL ACG2025-reference-implementation/ACG2025-reference-implementation.csproj
  ```

- **MCTS Engine (MCTS_ENGINE)**
  ```sh
  dotnet build -c Release -p:DefineConstants=MCTS_ENGINE ACG2025-reference-implementation/ACG2025-reference-implementation.csproj
  ```

- **Alpha-Beta Pruning Engine (ALPHA_BETA_ENGINE)**
  ```sh
  dotnet build -c Release -p:DefineConstants=ALPHA_BETA_ENGINE ACG2025-reference-implementation/ACG2025-reference-implementation.csproj
  ```

Upon successful build, an executable file `ACG2025-reference-implementation` with the specified functionality will be generated in the `ACG2025-reference-implementation/bin/Release/net8.0/` directory.

### 4. Tool Usage

This implementation includes three main tools plus two game engines for playing Reversi. These tools and engines are enabled by specifying appropriate symbols in the build commands mentioned above.

#### 4.1. N-Tuple System Structure Optimization (OPTIMIZE_NTUPLE)

This tool uses BRKGA to search for optimal n-tuple structures.

**Example Commands:**

```sh
# Start search from scratch
./ACG2025-reference-implementation/bin/Release/net8.0/ACG2025-reference-implementation \
    ntuple_optimizer_config.json \
    brkga_config.json \
    td_config.json \
    10 12 100

# Resume search from existing pool file
./ACG2025-reference-implementation/bin/Release/net8.0/ACG2025-reference-implementation \
    ntuple_optimizer_config.json \
    brkga_config.json \
    td_config.json \
    10 12 100 pool.bin
```

**Arguments:**
- `args[0]`: n-tuple optimization overall configuration file (`ntuple_optimizer_config.json`)
- `args[1]`: BRKGA configuration file (`brkga_config.json`)
- `args[2]`: TD learning configuration file (`td_config.json`)
- `args[3]`: n-tuple size (e.g., `10`)
- `args[4]`: number of n-tuples (e.g., `12`)
- `args[5]`: number of BRKGA generations (e.g., `100`)
- `args[6]` (optional): pool file to resume search (`pool.bin`)

#### 4.2. Self-Play Reinforcement Learning (RL_SELFPLAY)

This tool uses AlphaZero-style self-play reinforcement learning with MCTS to learn parameters (weights) of evaluation functions with optimized n-tuple structures. It generates games through self-play using MCTS and optimizes the value function parameters by minimizing binary cross-entropy between predictions and actual game outcomes.

**Example Commands:**

```sh
# Continue learning with existing weights file
./ACG2025-reference-implementation/bin/Release/net8.0/ACG2025-reference-implementation \
    selfplay_config.json \
    value_func_weights.bin 10

# Start learning with zero-initialized weights
./ACG2025-reference-implementation/bin/Release/net8.0/ACG2025-reference-implementation \
    selfplay_config.json \
    value_func_weights.bin 10 zero
```

**Arguments:**
- `args[0]`: Self-play reinforcement learning configuration file (`selfplay_config.json`)
- `args[1]`: Evaluation function weights file (`value_func_weights.bin`). An error occurs if it doesn't exist.
- `args[2]`: Number of training cycles (e.g., `10`)
- `args[3]` (optional): Specify `zero` to initialize the weights file with zeros before starting learning.

#### 4.3. Evaluation Function Generation from Pool (DECODE_POOL)

This tool extracts highest-fitness individuals (n-tuple structures) from the pool file (`pool.bin`) generated by the `OPTIMIZE_NTUPLE` tool and generates corresponding evaluation function files (`.bin`) and n-tuple definition files (`.txt`).

**Example Commands:**

```sh
# Decode top 3 individuals from pool file and generate evaluation functions with 12 10-tuples
./ACG2025-reference-implementation/bin/Release/net8.0/ACG2025-reference-implementation \
    pool.bin 3 10 12
```

**Arguments:**
- `args[0]`: BRKGA pool file (`pool.bin`)
- `args[1]`: Number of top individuals to decode (e.g., `3`)
- `args[2]`: n-tuple size (e.g., `10`)
- `args[3]`: number of n-tuples (e.g., `12`)
- `args[4]` (optional): number of moves per phase in evaluation function (default: `60`)

Running this tool generates `value_func_weights_idv{i}.bin` and `ntuples_idv{i}.txt` in the current directory.

#### 4.4. MCTS Engine (MCTS_ENGINE)

The MCTS (Monte Carlo Tree Search) engine implements a PUCT-based search algorithm for strong Reversi gameplay. This engine uses n-tuple-based evaluation functions to guide Monte Carlo tree search.

**Example Commands:**

```sh
# Run MCTS engine with default parameters
./ACG2025-reference-implementation/bin/Release/net8.0/ACG2025-reference-implementation
```

The MCTS engine supports the NBoard protocol for communication with external GUIs, allowing it to run on the NBoard GUI application ( http://www.orbanova.com/nboard/ ). It loads evaluation function weights from `params/value_func_weights.bin` by default.

**Key Features:**
- PUCT (Predictor + Upper Confidence bounds applied to Trees) algorithm
- n-tuple-based position evaluation
- Configurable simulation count and search parameters
- NBoard protocol compatibility for integration with NBoard GUI application

#### 4.5. Alpha-Beta Pruning Engine (ALPHA_BETA_ENGINE)

The Alpha-Beta Pruning engine implements classical minimax search with alpha-beta pruning, transposition tables, and move ordering for efficient and strong Reversi gameplay.

**Example Commands:**

```sh
# Run Alpha-Beta engine with default parameters
./ACG2025-reference-implementation/bin/Release/net8.0/ACG2025-reference-implementation
```

The Alpha-Beta engine also supports the NBoard protocol, allowing it to run on the NBoard GUI application ( http://www.orbanova.com/nboard/ ), and loads evaluation function weights from `params/value_func_weights.bin` by default.

**Key Features:**
- Alpha-beta pruning with transposition table
- Iterative deepening search
- Advanced move ordering techniques
- n-tuple-based evaluation function
- Configurable search depth based on game phase
- NBoard protocol compatibility for integration with NBoard GUI application

#### 4.6. Visualization Tools

The `VisualizationTools/` directory contains Python scripts for analyzing and visualizing the results of optimization and training processes.

##### 4.6.1. N-Tuple Visualization (`draw_ntuples.py`)

This script visualizes n-tuple structures on an 8x8 Othello board, helping to understand the spatial patterns captured by optimized n-tuples.

**Requirements:**
- Python 3.x
- matplotlib
- numpy

**Usage:**
```sh
cd VisualizationTools
python3 draw_ntuples.py <ntuple_file.txt>
```

**Example:**
```sh
python3 draw_ntuples.py ntuples_idv1.txt
```

The script reads n-tuple definition files (generated by the `DECODE_POOL` tool) and displays each n-tuple as a grid pattern, where black squares represent the positions included in that n-tuple.

##### 4.6.2. Fitness History Plotting (`plot_fitness_history.py`)

This script plots the fitness evolution during BRKGA optimization, showing how the population fitness improves over generations.

**Requirements:**
- Python 3.x
- matplotlib

**Usage:**
```sh
cd VisualizationTools
python3 plot_fitness_history.py <fitness_history_file1> [fitness_history_file2] ...
```

**Example:**
```sh
python3 plot_fitness_history.py ../fitness_history.txt
```

The script displays four lines showing the best, worst, median, and average fitness values across generations. Multiple fitness history files can be concatenated for visualization of extended optimization runs.

### 5. Configuration File Structure

The following shows the structure of configuration files used by each tool and parameter descriptions. Please refer to the template files in the `ConfigFileTemplates/` directory and adjust parameters as needed.

#### 5.1. N-Tuple Optimization Configuration File (`ntuple_optimizer_config.json`)

```json
{
  "NumThreads": 8,
  "NumTrainData": 10000,
  "NumTestData": 10000,
  "TrainDataVariationFactor": 0.05,
  "NumSimulations": 3200,
  "TrainDataUpdateInterval": 100
}
```

**Parameter Descriptions:**
- `NumThreads`: The number of threads to use for parallel processing during optimization. 
- `NumTrainData`: The number of training game data used for evaluating each n-tuple structure.
- `NumTestData`: The number of test game data used for measuring evaluation function performance after training.
- `TrainDataVariationFactor`: A value from 0 to 1 that controls the diversity of training data.
- `NumSimulations`: The number of simulations used for search at each position.
- `TrainDataUpdateInterval`: Updates training data every specified number of generations.

#### 5.2. BRKGA Configuration File (`brkga_config.json`)

```json
{
  "PopulationSize": 100,
  "EliteRate": 0.2,
  "MutantRate": 0.2,
  "EliteInheritanceProb": 0.7,
  "LearningRateForEval": 0.1,
  "NumEpochsForEval": 20,
  "PoolFileName": "pool",
  "FitnessHistoryFileName": "fitness_history"
}
```

**Parameter Descriptions:**
- `PopulationSize`: The number of individuals per generation in the genetic algorithm.
- `EliteRate`: The proportion of excellent individuals in the population (0 to 1).
- `MutantRate`: The proportion of mutant individuals in the population (0 to 1).
- `EliteInheritanceProb`: The probability of inheriting elite individual genes during crossover.
- `LearningRateForEval`: The learning rate of supervised learning used when evaluating individuals.
- `NumEpochsForEval`: The number of supervised learning epochs used for evaluating each individual.
- `PoolFileName`: Base name for pool files generated during the evolutionary process.
- `FitnessHistoryFileName`: File name for recording fitness progression of each generation.

#### 5.3. TD Learning Configuration File (`td_config.json`)

```json
{
  "NumEpisodes": 250000,
  "NumInitialRandomMoves": 1,
  "LearningRate": 0.2,
  "DiscountRate": 1,
  "InitialExplorationRate": 0.2,
  "FinalExplorationRate": 0.1,
  "EligibilityTraceFactor": 0.5,
  "HorizonCutFactor": 0.1,
  "TCLFactor": 2.7,
  "WeightsFileName": "value_func_weights_td",
  "SaveWeightsInterval": 10000,
  "SaveOnlyLatestWeights": true
}
```

**Parameter Descriptions:**
- `NumEpisodes`: The number of games to run in TD learning.
- `NumInitialRandomMoves`: The number of random moves at the start of each game.
- `LearningRate`: The learning rate for weight updates in TD learning (positive real number).
- `DiscountRate`: The discount rate for future rewards (0 to 1).
- `InitialExplorationRate`: The exploration rate of ε-greedy policy at the start of learning.
- `FinalExplorationRate`: The exploration rate of ε-greedy policy at the end of learning.
- `EligibilityTraceFactor`: Eligibility trace factor. The λ parameter of TD(λ) (0 to 1).
- `HorizonCutFactor`: Horizon cut factor.
- `TCLFactor`: TCL factor. Parameter related to Temporal Coherence Learning.
- `WeightsFileName`: Weights file name. Base name for files that save weights after learning.
- `SaveWeightsInterval`: Weights save interval. Saves weights every specified number of episodes.
- `SaveOnlyLatestWeights`: Whether to keep only the latest weights file (true) or all saved weights files (false).

#### 5.4. Self-Play Learning Configuration File (`selfplay_config.json`)

```json
{
  "NumThreads": 8,
  "NumSamplingMoves": 30,
  "NumSimulations": 800,
  "RootDirichletAlpha": 0.3,
  "RootExplorationFraction": 0.25,
  "NumGamesInBatch": 500000,
  "NumEpoch": 200,
  "StartWithRandomTrainData": true,
  "LearningRate": 1.0,
  "RootValueFraction": 0.0,
  "WeightsFileName": "value_func_weights_sp"
}
```

**Parameter Descriptions:**
- `NumThreads`: The number of threads used for parallel execution.
- `NumSamplingMoves`: The number of moves made probabilistically based on MCTS search results in each game.
- `NumSimulations`: The number of simulations to run in MCTS.
- `RootDirichletAlpha`: Root Dirichlet alpha parameter. The α value of Dirichlet noise at the root node in MCTS search.
- `RootExplorationFraction`: Root exploration fraction. The proportion of Dirichlet noise used for exploration at the root node.
- `NumGamesInBatch`: Number of games in batch. The number of games included in one learning batch.
- `NumEpoch`: Number of epochs. The number of epochs to run in self-play learning.
- `StartWithRandomTrainData`: Start with random training data. When true, starts with random training data.
- `LearningRate`: Learning rate. The learning rate for the n-tuple value function.
- `RootValueFraction`: Root value fraction. The fraction of training loss from root evaluation scores vs final game outcomes (0.0 = final result only, 1.0 = MCTS evaluations only).
- `WeightsFileName`: Weights file name. Base name for files that save weights after learning.

---

## Japanese

## 日本語

### 1. 概要

本プロジェクトは、論文「Mastering Othello with genetic algorithm and reinforcement learning」で提案した手法のリファレンス実装です。本実装は、ゲームルールと盤面対称性以外のドメイン知識を必要としない、リバーシの効率的な学習手法を提示しています。

本手法は、遺伝的アルゴリズムベースのn-tuple最適化と自己対局強化学習を組み合わせることで、強力な対局性能を実現します。主要な新規性は、Biased Random-Key Genetic Algorithm (BRKGA) を用いてn-tuple構造を最適化しながら、自己対局を通じて訓練データを生成することで、既存の棋譜やドメイン固有の戦略的知識への依存を排除したことです。

具体的には、以下の2つの主要なフェーズから構成されています。

1.  **n-tuple構造最適化**: BRKGAを用いて、特徴抽出のための最適なn-tupleの形状と組み合わせを進化させます。遺伝的アルゴリズムの各個体は空間的に連結されたn-tupleの集合を表し、適応度は各個体のn-tupleを用いてTD(λ)学習で価値関数を訓練した後、テストデータにおける価値関数の予測と実際の結果との間のクロスエントロピー損失の逆数として定義されます。
2.  **自己対局強化学習**: 最適化されたn-tupleを取得後、モンテカルロ木探索（MCTS）を用いたAlphaZeroスタイルの自己対局により価値関数パラメータをさらに洗練し、訓練サイクルごとに50万ゲームを生成します。

### 2. ディレクトリ・ファイル構成

本プロジェクトの主要なディレクトリとファイルの役割は以下の通りです。

-   `ACG2025-reference-implementation.sln`: Visual Studio用のソリューションファイル。
-   `ACG2025-reference-implementation/`: プロジェクトのソースコードが含まれるディレクトリ。
    -   `Program.cs`: メインのエントリーポイント。ビルド時に定義するシンボルによって、実行される機能（ツール）が切り替わります。
    -   `Engines/`: PUCTアルゴリズムを用いたMCTSエンジンと置換表付きα-β枝刈りエンジンを含むゲームエンジン。
    -   `Evaluation/`: 評価関数に関連するクラス。
    -   `Learn/`: TD学習、自己対局、BRKGAによるn-tuple最適化など、機械学習アルゴリズムの実装。
    -   `NTupleSystem/`: N-Tuple Systemの構造や管理を行うクラス。
    -   `Reversi/`: リバーシのルール、盤面表現、着手生成など、ゲームの基本的なロジック。
    -   `Search/`: 探索アルゴリズム（α-β探索、MCTS）の実装。
    -   `Protocols/`: NBoardプロトコルなど、思考エンジンを外部のGUIと通信させるためのインターフェース。NBoard GUIアプリケーション（ http://www.orbanova.com/nboard/ ）との統合に対応。
    -   `Utils/`: 補助的なユーティリティクラス。
-   `ConfigFileTemplates/`: 各ツールで使用する設定ファイル（`.json`）のテンプレートが格納されています。これらのファイルを任意の作業ディレクトリにコピーして使用してください。
-   `VisualizationTools/`: 結果の可視化とデータ分析のためのPythonスクリプト。
    -   `draw_ntuples.py`: n-tuple構造を8x8のボードグリッド上で視覚化します。n-tuple定義ファイル（`.txt`）を入力として、パターンを表示します。
    -   `plot_fitness_history.py`: BRKGAによる最適化における適応度の変化をプロットします。n-tuple最適化ツールによって生成された適応度履歴ファイルを入力として、世代を通じた最高、最低、中央値、平均適応度を表示します。

### 3. ビルド方法

本プロジェクトは .NET 8 で開発されています。.NET 8 SDKがインストールされている環境でビルドできます。使用したいツールに応じて、ビルド時にプリプロセッサシンボルを指定します。

**依存関係:**
本プロジェクトは以下のNuGetパッケージに依存しています：
- **MathNet.Numerics** (バージョン 5.0.0): MCTS実装で統計分布（特にディリクレ分布）を使用するために必要です。

`dotnet build`を実行すると、必要なNuGetパッケージが自動的にダウンロードされてインストールされます。

以下に、各ツールをビルドするためのコマンドを示します。

- **N-Tuple Systemの構造最適化 (OPTIMIZE_NTUPLE)**
  ```sh
  dotnet build -c Release -p:DefineConstants=OPTIMIZE_NTUPLE ACG2025-reference-implementation/ACG2025-reference-implementation.csproj
  ```

- **自己対局強化学習 (RL_SELFPLAY)**
  ```sh
  dotnet build -c Release -p:DefineConstants=RL_SELFPLAY ACG2025-reference-implementation/ACG2025-reference-implementation.csproj
  ```

- **プールからの評価関数生成 (DECODE_POOL)**
  ```sh
  dotnet build -c Release -p:DefineConstants=DECODE_POOL ACG2025-reference-implementation/ACG2025-reference-implementation.csproj
  ```

- **MCTSエンジン (MCTS_ENGINE)**
  ```sh
  dotnet build -c Release -p:DefineConstants=MCTS_ENGINE ACG2025-reference-implementation/ACG2025-reference-implementation.csproj
  ```

- **α-β法エンジン (ALPHA_BETA_ENGINE)**
  ```sh
  dotnet build -c Release -p:DefineConstants=ALPHA_BETA_ENGINE ACG2025-reference-implementation/ACG2025-reference-implementation.csproj
  ```

ビルドが成功すると、`ACG2025-reference-implementation/bin/Release/net8.0/` ディレクトリに、指定した機能を持つ実行ファイル `ACG2025-reference-implementation` が生成されます。

### 4. ツールの使用方法

本実装には、3つの主要なツールと、リバーシ対局のための2つのゲームエンジンが含まれています。これらのツールとエンジンは、前述のビルドコマンドで適切なシンボルを指定することで有効になります。

#### 4.1. N-Tuple Systemの構造最適化 (OPTIMIZE_NTUPLE)

このツールはBRKGAを用いて最適なn-tupleの構造を探索します。

**実行コマンド例:**

```sh
# ゼロから探索を開始する場合
./ACG2025-reference-implementation/bin/Release/net8.0/ACG2025-reference-implementation \
    ntuple_optimizer_config.json \
    brkga_config.json \
    td_config.json \
    10 12 100

# 既存のプールファイルから探索を再開する場合
./ACG2025-reference-implementation/bin/Release/net8.0/ACG2025-reference-implementation \
    ntuple_optimizer_config.json \
    brkga_config.json \
    td_config.json \
    10 12 100 pool.bin
```

**引数:**
- `args[0]`: n-tuple最適化の全体設定ファイル (`ntuple_optimizer_config.json`)
- `args[1]`: BRKGAの設定ファイル (`brkga_config.json`)
- `args[2]`: TD学習の設定ファイル (`td_config.json`)
- `args[3]`: n-tupleのサイズ (例: `10`)
- `args[4]`: n-tupleの数 (例: `12`)
- `args[5]`: BRKGAの世代数 (例: `100`)
- `args[6]` (オプション): 探索を再開するためのプールファイル (`pool.bin`)

#### 4.2. 自己対局強化学習 (RL_SELFPLAY)

このツールは、最適化されたn-tuple構造を持つ評価関数のパラメータ（重み）を、AlphaZeroスタイルの自己対局強化学習とMCTSを用いて学習します。MCTSを使用した自己対局によってゲームを生成し、価値関数の予測と実際のゲーム結果との間のバイナリクロスエントロピーを最小化することで価値関数パラメータを最適化します。

**実行コマンド例:**

```sh
# 既存の重みファイルを用いて学習を継続する場合
./ACG2025-reference-implementation/bin/Release/net8.0/ACG2025-reference-implementation \
    selfplay_config.json \
    value_func_weights.bin 10

# 重みをゼロで初期化して学習を開始する場合
./ACG2025-reference-implementation/bin/Release/net8.0/ACG2025-reference-implementation \
    selfplay_config.json \
    value_func_weights.bin 10 zero
```

**引数:**
- `args[0]`: 自己対局強化学習の設定ファイル (`selfplay_config.json`)
- `args[1]`: 評価関数の重みファイル (`value_func_weights.bin`)。存在しない場合はエラーになります。
- `args[2]`: 訓練サイクル数 (例: `10`)
- `args[3]` (オプション): `zero` を指定すると、重みファイルをゼロで初期化してから学習を開始します。

#### 4.3. プールからの評価関数生成 (DECODE_POOL)

`OPTIMIZE_NTUPLE` ツールによって生成されたプールファイル (`pool.bin`) から、適応度上位の個体（n-tuple構造）を取り出し、それに対応する評価関数ファイル (`.bin`) とn-tuple定義ファイル (`.txt`) を生成します。

**実行コマンド例:**

```sh
# プールファイルから上位3個体をデコードし、10-tupleが12個の評価関数を生成
./ACG2025-reference-implementation/bin/Release/net8.0/ACG2025-reference-implementation \
    pool.bin 3 10 12
```

**引数:**
- `args[0]`: BRKGAのプールファイル (`pool.bin`)
- `args[1]`: デコードする上位個体の数 (例: `3`)
- `args[2]`: n-tupleのサイズ (例: `10`)
- `args[3]`: n-tupleの数 (例: `12`)
- `args[4]` (オプション): 評価関数の1フェーズあたりの手数 (デフォルト: `60`)

このツールを実行すると、カレントディレクトリに `value_func_weights_idv{i}.bin` と `ntuples_idv{i}.txt` が生成されます。

#### 4.4. MCTSエンジン (MCTS_ENGINE)

MCTSエンジンは、強力なリバーシ対局のためのPUCTベースの探索アルゴリズムを実装しています。このエンジンは、n-tuple系の評価関数を用いてモンテカルロ木探索による探索を実行します。

**実行コマンド例:**

```sh
# デフォルトパラメータでMCTSエンジンを実行
./ACG2025-reference-implementation/bin/Release/net8.0/ACG2025-reference-implementation
```

MCTSエンジンは外部GUIとの通信にNBoardプロトコルをサポートしており、NBoard GUIアプリケーション（ http://www.orbanova.com/nboard/ ）上で動作させることが可能です。デフォルトで `params/value_func_weights.bin` から評価関数の重みを読み込みます。

**主な機能:**
- PUCT (Predictor + Upper Confidence bounds applied to Trees) アルゴリズム
- n-tupleによる局面評価
- シミュレーション回数や探索パラメータを設定可能
- NBoard GUIアプリケーションとの統合のためのNBoardプロトコル対応

#### 4.5. α-β法エンジン (ALPHA_BETA_ENGINE)

α-β法エンジンは、効率的で強力なリバーシ対局のために、α-β枝刈り、置換表、着手順序付けを備えた古典的なミニマックス探索を実装しています。

**実行コマンド例:**

```sh
# デフォルトパラメータでα-β法エンジンを実行
./ACG2025-reference-implementation/bin/Release/net8.0/ACG2025-reference-implementation
```

α-β法エンジンもNBoardプロトコルをサポートしており、NBoard GUIアプリケーション（ http://www.orbanova.com/nboard/ ）上で動作させることが可能です。デフォルトで `params/value_func_weights.bin` から評価関数の重みを読み込みます。

**主な機能:**
- 置換表付きα-β枝刈り
- 反復深化探索
- 高度な着手順序付け技法
- n-tuple系評価関数
- ゲーム局面に基づく探索深度の設定
- NBoard GUIアプリケーションとの統合のためのNBoardプロトコル対応

#### 4.6. 可視化ツール

`VisualizationTools/` ディレクトリには、最適化と訓練プロセスの結果を分析・可視化するためのPythonスクリプトが含まれています。

##### 4.6.1. N-Tuple可視化 (`draw_ntuples.py`)

このスクリプトは、8x8のオセロ盤面上でn-tuple構造を可視化し、最適化されたn-tupleによって捉えられる空間パターンの理解を助けます。

**必要環境:**
- Python 3.x
- matplotlib
- numpy

**使用方法:**
```sh
cd VisualizationTools
python3 draw_ntuples.py <ntuple_file.txt>
```

**実行例:**
```sh
python3 draw_ntuples.py ntuples_idv1.txt
```

スクリプトは、n-tuple定義ファイル（`DECODE_POOL`ツールによって生成）を読み込み、各n-tupleをグリッドパターンとして表示します。黒い四角はそのn-tupleに含まれる位置を表します。

##### 4.6.2. 適応度履歴プロット (`plot_fitness_history.py`)

このスクリプトは、BRKGA最適化における適応度の進化をプロットし、世代を通じて集団の適応度がどのように改善されるかを表示します。

**必要環境:**
- Python 3.x
- matplotlib

**使用方法:**
```sh
cd VisualizationTools
python3 plot_fitness_history.py <fitness_history_file1> [fitness_history_file2] ...
```

**実行例:**
```sh
python3 plot_fitness_history.py ../fitness_history.txt
```

スクリプトは、世代を通じた最高、最低、中央値、平均値を示す4つの線を表示します。複数の適応度履歴ファイルを連結することができます。

### 5. 設定ファイルの構造

各ツールで使用する設定ファイルの構造とパラメータの説明を以下に示します。`ConfigFileTemplates/` ディレクトリにあるテンプレートファイルを参考に、必要に応じてパラメータを調整してください。

#### 5.1. N-Tuple最適化設定ファイル (`ntuple_optimizer_config.json`)

```json
{
  "NumThreads": 8,
  "NumTrainData": 10000,
  "NumTestData": 10000,
  "TrainDataVariationFactor": 0.05,
  "NumSimulations": 3200,
  "TrainDataUpdateInterval": 100
}
```

**パラメータ説明:**
- `NumThreads`: 最適化処理中の並列処理に使用するスレッド数。
- `NumTrainData`: 各n-tuple構造の評価に使用する訓練用ゲームデータの数。
- `NumTestData`: 学習後の評価関数の性能測定に使用するテスト用ゲームデータの数。
- `TrainDataVariationFactor`: 0から1の値で、訓練データの多様性を制御。
- `NumSimulations`: 各局面での探索に使用するシミュレーション数。
- `TrainDataUpdateInterval`: 指定した世代数ごとに訓練用データを更新。

#### 5.2. BRKGA設定ファイル (`brkga_config.json`)

```json
{
  "PopulationSize": 100,
  "EliteRate": 0.2,
  "MutantRate": 0.2,
  "EliteInheritanceProb": 0.7,
  "LearningRateForEval": 0.1,
  "NumEpochsForEval": 20,
  "PoolFileName": "pool",
  "FitnessHistoryFileName": "fitness_history"
}
```

**パラメータ説明:**
- `PopulationSize`: 遺伝的アルゴリズムの1世代あたりの個体数。
- `EliteRate`: 集団における優秀な個体の比率（0から1）。
- `MutantRate`: 集団における突然変異個体の比率（0から1）。
- `EliteInheritanceProb`: 交叉時にエリート個体の遺伝子を継承する確率。
- `LearningRateForEval`: 個体の評価時に使用する教師あり学習の学習率。
- `NumEpochsForEval`: 各個体の評価に使用する教師あり学習のエポック数。
- `PoolFileName`: 進化過程で生成されるプールファイルのベース名。
- `FitnessHistoryFileName`: 各世代の適応度の推移を記録するファイル名。

#### 5.3. TD学習設定ファイル (`td_config.json`)

```json
{
  "NumEpisodes": 250000,
  "NumInitialRandomMoves": 1,
  "LearningRate": 0.2,
  "DiscountRate": 1,
  "InitialExplorationRate": 0.2,
  "FinalExplorationRate": 0.1,
  "EligibilityTraceFactor": 0.5,
  "HorizonCutFactor": 0.1,
  "TCLFactor": 2.7,
  "WeightsFileName": "value_func_weights_td",
  "SaveWeightsInterval": 10000,
  "SaveOnlyLatestWeights": true
}
```

**パラメータ説明:**
- `NumEpisodes`: TD学習で実行するゲーム数。
- `NumInitialRandomMoves`: ゲーム開始時のランダムな着手数。
- `LearningRate`: TD学習の重み更新における学習率（正の実数）。
- `DiscountRate`: 将来の報酬に対する割引率（0から1）。
- `InitialExplorationRate`: 学習開始時のε-greedyポリシーの探索率。
- `FinalExplorationRate`: 学習終了時のε-greedyポリシーの探索率。
- `EligibilityTraceFactor`: 適格度トレース係数。TD(λ)のλパラメータ（0から1）。
- `HorizonCutFactor`: horizon cut係数。
- `TCLFactor`: TCL係数。Temporal Coherence Learning関連のパラメータ。
- `WeightsFileName`: 重みファイル名。学習後の重みを保存するファイルのベース名。
- `SaveWeightsInterval`: 重み保存間隔。指定したエピソード数ごとに重みを保存。
- `SaveOnlyLatestWeights`: 最新の重みファイルのみを保持するか（true）、全ての保存された重みファイルを保持するか（false）。

#### 5.4. 自己対局学習設定ファイル (`selfplay_config.json`)

```json
{
  "NumThreads": 8,
  "NumSamplingMoves": 30,
  "NumSimulations": 800,
  "RootDirichletAlpha": 0.3,
  "RootExplorationFraction": 0.25,
  "NumGamesInBatch": 500000,
  "NumEpoch": 200,
  "StartWithRandomTrainData": true,
  "LearningRate": 1.0,
  "RootValueFraction": 0.0,
  "WeightsFileName": "value_func_weights_sp"
}
```

**パラメータ説明:**
- `NumThreads`: 並列実行に使用するスレッド数。
- `NumSamplingMoves`: 各ゲームでMCTS探索結果に基づいて確率的に着手を行う回数。
- `NumSimulations`: MCTSで実行するシミュレーション数。
- `RootDirichletAlpha`: ルートディリクレαパラメータ。MCTS探索のルートノードにおけるディリクレノイズのα値。
- `RootExplorationFraction`: ルート探索率。ルートノードでの探索に使用するディリクレノイズの比率。
- `NumGamesInBatch`: バッチ内ゲーム数。1つの学習バッチに含まれるゲーム数。
- `NumEpoch`: エポック数。自己対局学習で実行するエポック数。
- `StartWithRandomTrainData`: ランダム訓練データ開始。trueの場合、ランダムな訓練データから開始。
- `LearningRate`: 学習率。n-tuple価値関数の学習率。
- `RootValueFraction`: MCTS評価値混合率。訓練時の損失関数において、MCTS評価スコアと最終ゲーム結果の混合比率（0.0=最終結果のみ使用、1.0=MCTS評価のみ使用）。
- `WeightsFileName`: 重みファイル名。学習後の重みを保存するファイルのベース名。
